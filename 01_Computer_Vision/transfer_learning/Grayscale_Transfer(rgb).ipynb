{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0723aca9-36c2-4cc7-8f32-d4fc0bc6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Activation, Concatenate\n",
    "from keras import Sequential\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Different Transfer learning rate/models\n",
    "#https://keras.io/api/applications/\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f58a89-9e62-441d-bd26-13fcaf605aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000008</td>\n",
       "      <td>ppt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000027</td>\n",
       "      <td>csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000039</td>\n",
       "      <td>xml</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000067</td>\n",
       "      <td>xml</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000081</td>\n",
       "      <td>txt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName FileType  Class\n",
       "0    000008      ppt      0\n",
       "1    000027      csv      1\n",
       "2    000039      xml      2\n",
       "3    000067      xml      2\n",
       "4    000081      txt      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"grayscale\"\n",
    "#test_dir = \"../input/test/test/\"\n",
    "train_df = pd.read_csv('file_types.csv')\n",
    "train_df['ImageName'] = train_df['ImageName'].astype(str)\n",
    "train_df['ImageName'] = train_df['ImageName'].astype(str).str.zfill(6)\n",
    "train_df['Class'] = pd.factorize(train_df['FileType'])[0] \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e45d6e-04af-495e-a69c-3c105bf45f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100\n",
    "height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b7fd89-4ac1-45ba-a217-22bf42f9076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def extract_scalogram(path):\n",
    "    #height =  img_height# pixels in length\n",
    "    #width = img_width # pixels in width\n",
    "  \n",
    "    imgs = np.empty((0, width, height, 3)) \n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        \n",
    "        if filename.endswith(\".png\"):\n",
    "\n",
    "            img = Image.open(os.path.join(path, filename)).convert('RGB')\n",
    "\n",
    "            imgs = np.append(imgs, np.array(img).reshape((1, width, height, 3)), axis=0)\n",
    "    \n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adf235d-380a-40dc-8bf0-ba6050206a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y_train = train_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbaff7-48ba-4ec6-afd1-303948f0b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = extract_scalogram(train_dir)\n",
    "\n",
    "y_train=to_categorical(y_train)\n",
    "\n",
    "print((X_train.shape,y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b84e95-a49a-4522-8414-6c60ce26d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_negative_one(img):\n",
    "    normalized_input = (img - np.amin(img)) / (np.amax(img) - np.amin(img))\n",
    "    return 2*normalized_input - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c2f71-d941-4ced-85ae-a0d66abf97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize_negative_one(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463187ab-ba0f-4aac-acc2-294876c3e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
    "    test_size=0.30, shuffle = True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test,\n",
    "    test_size=0.20, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee6ed0-3370-4af6-9d0f-b9022bbbff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)\n",
    "print('X_val: ', X_val.shape)\n",
    "print('y_val: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddae2b-7b81-4ed1-93df-b1827c297f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.0001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d130bb6-521d-4add-b89f-f05c20fb0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "train_generator = train_dategen.flow(X_train,  y_train, batch_size= batch_size)\n",
    "\n",
    "validation_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "validation_generator = validation_dategen.flow(X_val, y_val, batch_size= batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeaae1e-51fb-4bb6-9587-964d5016add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_accuracy', factor=.01, patience=3, min_lr=1e-5) #change learning rATE  to get the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb391dfb-b0ee-4305-960a-9afbadc8ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the googlenet model\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "\n",
    "base_model = InceptionV3(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "#base_model = ResNet50(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3)) #\n",
    "#base_model = ResNet101(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "#base_model = Xception(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height, 3))\n",
    "#base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "#base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "\n",
    "\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#changing the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e177a0e-32b8-4479-8066-1bdd80025a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f96b9c-c9bc-449c-a38c-c137f542d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7af488-9567-437a-9881-a185ae5cdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                    epochs = epochs, \n",
    "                    steps_per_epoch = X_train.shape[0]//batch_size, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = X_val.shape[0]//batch_size, callbacks=[lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b7292-18ae-4d9d-9c5d-d2ddd3a2e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,1) \n",
    "\n",
    "#Loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19986562-efb8-4302-a666-1f7f67f0fc92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
