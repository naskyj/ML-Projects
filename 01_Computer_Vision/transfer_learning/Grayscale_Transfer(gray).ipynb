{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0723aca9-36c2-4cc7-8f32-d4fc0bc6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Activation, Concatenate\n",
    "from keras import Sequential\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Different Transfer learning rate/models\n",
    "#https://keras.io/api/applications/\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5f58a89-9e62-441d-bd26-13fcaf605aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000008</td>\n",
       "      <td>ppt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000027</td>\n",
       "      <td>csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000039</td>\n",
       "      <td>xml</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000067</td>\n",
       "      <td>xml</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000081</td>\n",
       "      <td>txt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName FileType  Class\n",
       "0    000008      ppt      0\n",
       "1    000027      csv      1\n",
       "2    000039      xml      2\n",
       "3    000067      xml      2\n",
       "4    000081      txt      3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"grayscale\"\n",
    "#test_dir = \"../input/test/test/\"\n",
    "train_df = pd.read_csv('file_types.csv')\n",
    "train_df['ImageName'] = train_df['ImageName'].astype(str)\n",
    "train_df['ImageName'] = train_df['ImageName'].astype(str).str.zfill(6)\n",
    "train_df['Class'] = pd.factorize(train_df['FileType'])[0] \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05e45d6e-04af-495e-a69c-3c105bf45f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100\n",
    "height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "188011a8-a0ca-42fe-ba41-cf4ccfd08c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((15797, 100, 100, 1), (15797, 14))\n"
     ]
    }
   ],
   "source": [
    "X_tr = []\n",
    "Y_tr = []\n",
    "imges = train_df['ImageName'].values\n",
    "for img_id in imges:\n",
    "    file = os.path.join(train_dir, img_id) + '.png'\n",
    "   \n",
    "    temp = cv2.imread(file) \n",
    "            \n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "    temp = np.expand_dims(temp, axis=2)\n",
    "    X_tr.append(temp)    \n",
    "    Y_tr.append(train_df[train_df['ImageName'] == img_id]['Class'].values[0])  \n",
    "X_tr = np.asarray(X_tr)\n",
    "Y_tr = to_categorical(Y_tr)\n",
    "#X_tr = X_tr.astype('float32')\n",
    "#X_tr /= 255\n",
    "#Y_tr = np.asarray(Y_tr)\n",
    "print((X_tr.shape,Y_tr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce59da01-ee6f-4413-af56-457b9b33c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
    "    test_size=0.20, shuffle = True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test,\n",
    "    test_size=0.50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3be1ba7b-5ff8-49fa-ac56-ee1732573b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (4528, 100, 100, 1)\n",
      "y_train:  (4528, 14)\n",
      "X_test:  (566, 100, 100, 1)\n",
      "y_test:  (566, 14)\n",
      "X_val:  (566, 100, 100, 1)\n",
      "y_val:  (566, 14)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)\n",
    "print('X_val: ', X_val.shape)\n",
    "print('y_val: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d837ff39-ed1c-43ff-aab1-be8f0d63286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Razaq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.0001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a92fe14d-5959-4ee3-9423-8579aeef9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "train_generator = train_dategen.flow(X_train,  y_train, batch_size= batch_size)\n",
    "\n",
    "validation_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "validation_generator = validation_dategen.flow(X_val, y_val, batch_size= batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "067194e6-7b0e-4169-af26-e3cecb31bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_accuracy', factor=.01, patience=3, min_lr=1e-5) #change learning rATE  to get the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3011e80b-998e-4e75-a204-16c5e28e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "#mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb391dfb-b0ee-4305-960a-9afbadc8ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the googlenet model\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "\n",
    "base_model = InceptionV3(include_top = False, weights = None, input_shape = (img_width,img_height,1))\n",
    "#base_model = ResNet50(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3)) #\n",
    "#base_model = ResNet101(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "#base_model = Xception(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height, 3))\n",
    "#base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,3))\n",
    "#base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (img_width,img_height,1))\n",
    "\n",
    "\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#changing the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "#https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n",
    "\n",
    "# #changing the last layer\n",
    "# for layer in base_model.layers:\n",
    "#   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2054962-2d2a-40e7-95ec-98d8f7350c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802208  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14)                28686     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,830,894\n",
      "Trainable params: 28,686\n",
      "Non-trainable params: 21,802,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4945a841-19b6-48c9-9a16-1c9b81e0497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c8ab759-147b-45f9-b159-ba5dceb2ce7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Razaq\\AppData\\Local\\Temp\\ipykernel_10020\\3948111818.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 26s 161ms/step - loss: 2.6329 - accuracy: 0.2340 - val_loss: 2.6265 - val_accuracy: 0.2316 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 24s 167ms/step - loss: 2.6190 - accuracy: 0.2471 - val_loss: 2.6134 - val_accuracy: 0.2279 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.6054 - accuracy: 0.2456 - val_loss: 2.6010 - val_accuracy: 0.2298 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5918 - accuracy: 0.2451 - val_loss: 2.5876 - val_accuracy: 0.2316 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 21s 152ms/step - loss: 2.5838 - accuracy: 0.2456 - val_loss: 2.5855 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5826 - accuracy: 0.2449 - val_loss: 2.5846 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5813 - accuracy: 0.2451 - val_loss: 2.5844 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5799 - accuracy: 0.2451 - val_loss: 2.5829 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 21s 151ms/step - loss: 2.5786 - accuracy: 0.2462 - val_loss: 2.5813 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5774 - accuracy: 0.2451 - val_loss: 2.5799 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5761 - accuracy: 0.2451 - val_loss: 2.5790 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5748 - accuracy: 0.2460 - val_loss: 2.5773 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 2.5734 - accuracy: 0.2458 - val_loss: 2.5766 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 23s 160ms/step - loss: 2.5724 - accuracy: 0.2447 - val_loss: 2.5755 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5710 - accuracy: 0.2451 - val_loss: 2.5744 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5696 - accuracy: 0.2449 - val_loss: 2.5727 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5684 - accuracy: 0.2456 - val_loss: 2.5714 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5671 - accuracy: 0.2456 - val_loss: 2.5710 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5658 - accuracy: 0.2451 - val_loss: 2.5688 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5646 - accuracy: 0.2449 - val_loss: 2.5678 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5635 - accuracy: 0.2451 - val_loss: 2.5668 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.5621 - accuracy: 0.2453 - val_loss: 2.5658 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5609 - accuracy: 0.2451 - val_loss: 2.5652 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5598 - accuracy: 0.2447 - val_loss: 2.5638 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5584 - accuracy: 0.2444 - val_loss: 2.5629 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.5572 - accuracy: 0.2449 - val_loss: 2.5604 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5557 - accuracy: 0.2451 - val_loss: 2.5598 - val_accuracy: 0.2353 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5544 - accuracy: 0.2449 - val_loss: 2.5580 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.5534 - accuracy: 0.2453 - val_loss: 2.5571 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5520 - accuracy: 0.2447 - val_loss: 2.5562 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 23s 160ms/step - loss: 2.5507 - accuracy: 0.2458 - val_loss: 2.5556 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5495 - accuracy: 0.2453 - val_loss: 2.5547 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.5484 - accuracy: 0.2451 - val_loss: 2.5532 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5472 - accuracy: 0.2451 - val_loss: 2.5506 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5460 - accuracy: 0.2456 - val_loss: 2.5507 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5445 - accuracy: 0.2460 - val_loss: 2.5472 - val_accuracy: 0.2353 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5435 - accuracy: 0.2456 - val_loss: 2.5474 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5422 - accuracy: 0.2451 - val_loss: 2.5473 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5410 - accuracy: 0.2464 - val_loss: 2.5476 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5398 - accuracy: 0.2451 - val_loss: 2.5453 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5385 - accuracy: 0.2462 - val_loss: 2.5435 - val_accuracy: 0.2353 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5376 - accuracy: 0.2449 - val_loss: 2.5423 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 23s 160ms/step - loss: 2.5363 - accuracy: 0.2447 - val_loss: 2.5416 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5349 - accuracy: 0.2453 - val_loss: 2.5404 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5338 - accuracy: 0.2453 - val_loss: 2.5391 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5326 - accuracy: 0.2451 - val_loss: 2.5391 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5315 - accuracy: 0.2444 - val_loss: 2.5378 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5303 - accuracy: 0.2453 - val_loss: 2.5350 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5291 - accuracy: 0.2451 - val_loss: 2.5365 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5281 - accuracy: 0.2444 - val_loss: 2.5330 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5265 - accuracy: 0.2451 - val_loss: 2.5315 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5257 - accuracy: 0.2447 - val_loss: 2.5292 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5244 - accuracy: 0.2447 - val_loss: 2.5316 - val_accuracy: 0.2224 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 23s 164ms/step - loss: 2.5232 - accuracy: 0.2444 - val_loss: 2.5282 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5221 - accuracy: 0.2447 - val_loss: 2.5300 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5211 - accuracy: 0.2444 - val_loss: 2.5265 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5196 - accuracy: 0.2451 - val_loss: 2.5267 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5186 - accuracy: 0.2456 - val_loss: 2.5256 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5173 - accuracy: 0.2453 - val_loss: 2.5240 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5165 - accuracy: 0.2451 - val_loss: 2.5231 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5150 - accuracy: 0.2458 - val_loss: 2.5206 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5138 - accuracy: 0.2458 - val_loss: 2.5207 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5126 - accuracy: 0.2458 - val_loss: 2.5194 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.5116 - accuracy: 0.2449 - val_loss: 2.5179 - val_accuracy: 0.2353 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.5104 - accuracy: 0.2451 - val_loss: 2.5168 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5093 - accuracy: 0.2447 - val_loss: 2.5166 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5085 - accuracy: 0.2442 - val_loss: 2.5146 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5072 - accuracy: 0.2453 - val_loss: 2.5152 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5058 - accuracy: 0.2456 - val_loss: 2.5124 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.5050 - accuracy: 0.2447 - val_loss: 2.5109 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 23s 163ms/step - loss: 2.5038 - accuracy: 0.2451 - val_loss: 2.5119 - val_accuracy: 0.2206 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.5026 - accuracy: 0.2444 - val_loss: 2.5099 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 21s 152ms/step - loss: 2.5013 - accuracy: 0.2458 - val_loss: 2.5089 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.5002 - accuracy: 0.2453 - val_loss: 2.5062 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.4993 - accuracy: 0.2449 - val_loss: 2.5077 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4982 - accuracy: 0.2442 - val_loss: 2.5054 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.4967 - accuracy: 0.2451 - val_loss: 2.5032 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 2.4957 - accuracy: 0.2453 - val_loss: 2.5037 - val_accuracy: 0.2206 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 2.4947 - accuracy: 0.2444 - val_loss: 2.5024 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.4937 - accuracy: 0.2442 - val_loss: 2.5000 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.4926 - accuracy: 0.2451 - val_loss: 2.4983 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 22s 157ms/step - loss: 2.4912 - accuracy: 0.2449 - val_loss: 2.4990 - val_accuracy: 0.2371 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4903 - accuracy: 0.2458 - val_loss: 2.4981 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.4894 - accuracy: 0.2447 - val_loss: 2.4982 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.4882 - accuracy: 0.2451 - val_loss: 2.4965 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 22s 158ms/step - loss: 2.4871 - accuracy: 0.2462 - val_loss: 2.4942 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4860 - accuracy: 0.2460 - val_loss: 2.4938 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4849 - accuracy: 0.2440 - val_loss: 2.4912 - val_accuracy: 0.2371 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4838 - accuracy: 0.2444 - val_loss: 2.4906 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 22s 155ms/step - loss: 2.4829 - accuracy: 0.2451 - val_loss: 2.4915 - val_accuracy: 0.2279 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.4815 - accuracy: 0.2456 - val_loss: 2.4905 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 22s 153ms/step - loss: 2.4808 - accuracy: 0.2451 - val_loss: 2.4908 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 2.4794 - accuracy: 0.2453 - val_loss: 2.4897 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.4783 - accuracy: 0.2462 - val_loss: 2.4865 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 2.4774 - accuracy: 0.2449 - val_loss: 2.4863 - val_accuracy: 0.2335 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.4762 - accuracy: 0.2458 - val_loss: 2.4814 - val_accuracy: 0.2316 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 22s 156ms/step - loss: 2.4750 - accuracy: 0.2451 - val_loss: 2.4844 - val_accuracy: 0.2224 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.4743 - accuracy: 0.2451 - val_loss: 2.4845 - val_accuracy: 0.2298 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 22s 154ms/step - loss: 2.4733 - accuracy: 0.2451 - val_loss: 2.4818 - val_accuracy: 0.2353 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 2.4722 - accuracy: 0.2449 - val_loss: 2.4810 - val_accuracy: 0.2298 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                    epochs = epochs, \n",
    "                    steps_per_epoch = X_train.shape[0]//batch_size, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = X_val.shape[0]//batch_size, callbacks=[lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e4e38c2-aa6d-4b7e-b6eb-b0e14a58f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "024e9884-24d6-441d-9fcc-43a99201b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38a950a9-b394-499d-a609-44782ef20b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  30,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 124,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 137,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139,\n",
       "          0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
       "          0]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12cef801-50c9-4b5b-b34d-0189d4a1dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00       124\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00        33\n",
      "          10       0.00      0.00      0.00       137\n",
      "          11       0.00      0.00      0.00        23\n",
      "          12       0.25      1.00      0.39       139\n",
      "          13       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.25       566\n",
      "   macro avg       0.02      0.07      0.03       566\n",
      "weighted avg       0.06      0.25      0.10       566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Razaq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Razaq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Razaq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b59de7-c563-4c58-8f19-e6401898ef89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
