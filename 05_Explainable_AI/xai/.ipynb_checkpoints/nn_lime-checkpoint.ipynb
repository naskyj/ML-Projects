{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-_Wka-vo3MR",
    "outputId": "5f2c07eb-8095-4d47-fd25-484d5abaf429"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lime\n",
    "import shap\n",
    "import lime.lime_tabular\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1C4Xju5azpqf",
    "outputId": "f075b508-a9e6-45f6-b155-5959072661af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d226857cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"xai.csv\", index_col=False)\n",
    "df.columns = [i.zfill(2) for i in df.columns]\n",
    "df.drop(axis=1, labels='Unnamed: 0', inplace=True)\n",
    "\n",
    "X = df.iloc[:, 0:256]\n",
    "y = df.Class\n",
    "\n",
    "original_feature_names = X.columns\n",
    "\n",
    "# Manually create a list of feature names with the original hexadecimal values\n",
    "feature_names = [f\"{original_feature_names[i]}\" for i in range(256)]\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "y = encoder.transform(y)\n",
    "y = np_utils.to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(256,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       114\n",
      "           1       0.70      0.65      0.67       208\n",
      "           2       0.66      0.58      0.62       219\n",
      "           3       0.29      0.30      0.29       105\n",
      "           4       0.89      0.91      0.90       785\n",
      "           5       0.52      0.39      0.44       197\n",
      "           6       0.81      0.83      0.82        66\n",
      "           7       0.71      0.78      0.75       767\n",
      "           8       0.61      0.25      0.36        55\n",
      "           9       0.38      0.45      0.41       180\n",
      "          10       0.92      0.85      0.88       121\n",
      "          11       0.85      0.88      0.86       602\n",
      "          12       0.79      0.85      0.82       131\n",
      "          13       0.81      0.68      0.74        92\n",
      "\n",
      "    accuracy                           0.75      3642\n",
      "   macro avg       0.70      0.66      0.67      3642\n",
      "weighted avg       0.75      0.75      0.75      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 3643it [07:55,  7.55it/s]                                                                       \n"
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(model, X_train.values, algorithm=\"permutation\", max_evals=1000)\n",
    "\n",
    "shap_values = explainer(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3642, 256, 14)\n",
      ".values =\n",
      "array([[[ 3.07042680e-03, -2.46339288e-02, -3.36864769e-04, ...,\n",
      "          4.36079032e-02, -5.29184022e-02,  7.21352487e-03],\n",
      "        [ 2.76534586e-03, -1.89432299e-03,  3.91620931e-06, ...,\n",
      "          1.22788309e-03, -4.35198904e-03,  1.70459522e-03],\n",
      "        [ 6.73480166e-06, -9.52963163e-04,  1.78183824e-04, ...,\n",
      "          1.31741242e-03, -2.70802603e-03, -1.79764116e-03],\n",
      "        ...,\n",
      "        [-1.33856065e-05,  6.27320249e-04,  1.01828382e-04, ...,\n",
      "          4.82343648e-03, -1.68936165e-03, -2.43344273e-03],\n",
      "        [-3.86140239e-10, -1.50454908e-02,  7.06977435e-04, ...,\n",
      "         -3.39024473e-03,  3.38510092e-05, -5.51206646e-05],\n",
      "        [-1.64033285e-08, -1.51734702e-03, -1.68446335e-02, ...,\n",
      "         -1.66251494e-03, -9.73037109e-04, -2.68864550e-05]],\n",
      "\n",
      "       [[ 1.13881501e-05, -1.38372018e-02, -2.01564149e-04, ...,\n",
      "          5.42591627e-02, -3.20906901e-02,  1.25640764e-04],\n",
      "        [-1.51583141e-08,  1.39565525e-03,  3.16943957e-05, ...,\n",
      "          2.58828571e-04, -5.14428544e-03,  2.18557753e-05],\n",
      "        [ 1.08813136e-06,  1.35237686e-03,  2.87880753e-03, ...,\n",
      "          8.93278163e-04, -4.85698305e-03,  2.37862196e-05],\n",
      "        ...,\n",
      "        [ 6.75493439e-07, -1.45309796e-04,  2.26442488e-03, ...,\n",
      "          2.82653142e-02, -4.22957865e-05, -2.21877480e-04],\n",
      "        [-8.77054436e-06, -1.19084278e-02, -1.46123736e-02, ...,\n",
      "          6.96598487e-03,  1.63209809e-05,  3.77873642e-04],\n",
      "        [-2.96288039e-06, -7.45293745e-04, -3.08506421e-03, ...,\n",
      "         -1.44978940e-02,  1.65467192e-04,  2.58251798e-06]],\n",
      "\n",
      "       [[-1.67562264e-12, -5.88597648e-02,  1.15594493e-06, ...,\n",
      "         -7.99909017e-04, -4.41347833e-02,  8.21709962e-03],\n",
      "        [ 4.59470905e-11,  1.13072279e-02,  1.42421098e-10, ...,\n",
      "          8.68616474e-06, -1.79348880e-03,  4.44203003e-06],\n",
      "        [ 5.58464425e-07,  1.15632654e-03,  7.12683982e-05, ...,\n",
      "          1.58567838e-04, -1.55248022e-03, -3.00556792e-03],\n",
      "        ...,\n",
      "        [ 1.26905562e-12,  4.87283013e-03, -2.00117321e-07, ...,\n",
      "         -1.85152890e-03, -1.95446848e-04, -3.75013564e-04],\n",
      "        [-1.73564231e-07, -7.82650276e-03, -4.10180849e-04, ...,\n",
      "          3.22841163e-04, -7.58322600e-04, -5.99046323e-03],\n",
      "        [-4.56813872e-12,  8.43884643e-03, -1.68769709e-05, ...,\n",
      "         -5.37533461e-03,  2.29262655e-03, -5.75623375e-04]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 8.69546358e-05, -2.99816933e-02,  1.27277840e-02, ...,\n",
      "          2.64237576e-04, -1.23311110e-02,  2.14857182e-03],\n",
      "        [-1.98014254e-05,  1.35641176e-03, -3.92576089e-04, ...,\n",
      "         -1.76699737e-03, -2.80365394e-05, -2.08820082e-04],\n",
      "        [ 1.90254118e-06, -2.91200152e-03,  9.13369644e-04, ...,\n",
      "         -2.01758765e-03, -1.63071207e-03,  6.08941111e-04],\n",
      "        ...,\n",
      "        [ 1.35621918e-04, -2.80684675e-04, -9.85226823e-03, ...,\n",
      "         -2.48063206e-03,  9.24575890e-04,  3.53866862e-04],\n",
      "        [ 6.45638083e-06, -6.87988792e-04, -3.70789154e-04, ...,\n",
      "          4.95344568e-04,  1.27647887e-03,  3.16628659e-04],\n",
      "        [ 6.29733922e-06, -1.19342736e-02, -8.87391666e-03, ...,\n",
      "          7.29515437e-05,  7.70652617e-04,  2.20360338e-05]],\n",
      "\n",
      "       [[ 6.83427073e-05, -3.32699303e-02, -1.67104364e-02, ...,\n",
      "         -5.37948982e-05, -6.27682514e-03, -1.97451689e-03],\n",
      "        [-1.07759010e-03,  9.13273510e-03, -4.94147428e-03, ...,\n",
      "          1.82652201e-03, -6.74541503e-04, -3.71710031e-04],\n",
      "        [ 1.36715626e-04,  1.44906068e-03, -8.47483530e-04, ...,\n",
      "         -2.57260666e-03,  1.13000545e-03,  5.57604558e-03],\n",
      "        ...,\n",
      "        [ 7.71526573e-05, -1.65873831e-03,  3.05938450e-03, ...,\n",
      "         -1.80281977e-03,  7.77263199e-04,  5.83091386e-04],\n",
      "        [ 3.25858245e-06,  6.74505616e-03,  1.80820450e-02, ...,\n",
      "         -4.82724724e-03,  2.49629374e-04,  1.03343592e-04],\n",
      "        [ 9.27339626e-04, -6.58249370e-03,  1.51568116e-02, ...,\n",
      "          2.47976482e-03,  1.01911169e-02, -6.16046846e-04]],\n",
      "\n",
      "       [[ 4.96892761e-06, -8.38316048e-03,  1.25073340e-03, ...,\n",
      "          2.71959201e-03, -3.98941636e-02,  1.59048363e-02],\n",
      "        [-1.50421489e-06, -2.09540175e-04,  1.27131722e-05, ...,\n",
      "          2.14535219e-04, -1.62428901e-03,  3.70535940e-03],\n",
      "        [ 6.26526505e-05,  2.20568748e-03, -1.80428334e-04, ...,\n",
      "          1.73778128e-03, -8.54748928e-03, -4.03310322e-04],\n",
      "        ...,\n",
      "        [ 3.35885207e-09,  2.21931797e-03,  8.65886273e-06, ...,\n",
      "         -5.13745428e-04, -7.35279016e-05, -4.30436349e-04],\n",
      "        [-3.59662882e-08, -1.10084284e-05, -1.28165012e-04, ...,\n",
      "         -3.73990378e-03, -2.32564587e-04, -9.96151338e-05],\n",
      "        [ 4.32639071e-05, -4.56947518e-03, -2.35012457e-02, ...,\n",
      "         -5.50064118e-03,  2.27573393e-04,  4.26757675e-03]]])\n",
      "\n",
      ".base_values =\n",
      "array([[0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375],\n",
      "       [0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375],\n",
      "       [0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375],\n",
      "       ...,\n",
      "       [0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375],\n",
      "       [0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375],\n",
      "       [0.01023038, 0.02920279, 0.04613212, ..., 0.21600365, 0.05148334,\n",
      "        0.03150375]])\n",
      "\n",
      ".data =\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [6, 5, 1, ..., 4, 3, 0],\n",
      "       [4, 7, 6, ..., 3, 6, 9],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(shap_values.shape)\n",
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w61tB6oOv-oa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features with Negative Impact on the Model:\n",
      "07 - 0.0082\n",
      "04 - 0.0064\n",
      "0b - 0.0044\n",
      "09 - 0.0041\n",
      "01 - 0.0025\n",
      "02 - 0.0023\n",
      "0d - 0.0020\n",
      "0c - 0.0018\n",
      "0a - 0.0016\n",
      "05 - 0.0013\n"
     ]
    }
   ],
   "source": [
    "mean_abs_shap_values = np.mean(np.abs(shap_values[0].values), axis=0)  \n",
    "\n",
    "sorted_feature_importances = sorted(enumerate(mean_abs_shap_values), key=lambda x: x[1], reverse=True)\n",
    "top_10_negative_features = sorted_feature_importances[:10]\n",
    "\n",
    "print(\"Top 10 Features with Negative Impact on the Model:\")\n",
    "for feature_idx, importance in top_10_negative_features:\n",
    "    print(f\"{feature_names[feature_idx]} - {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[(7, 0.008185287996704722), (4, 0.006375459232798194), (11, 0.004358678967834433), (9, 0.00406225611035695), (1, 0.002526873180391293), (2, 0.0023429387633662987), (13, 0.0019683888557206425), (12, 0.0018065659542205316), (10, 0.001590841297265665), (5, 0.0013093065526814367)] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_10_negative_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[(7, 0.008185287996704722), (4, 0.006375459232798194), (11, 0.004358678967834433), (9, 0.00406225611035695), (1, 0.002526873180391293), (2, 0.0023429387633662987), (13, 0.0019683888557206425), (12, 0.0018065659542205316), (10, 0.001590841297265665), (5, 0.0013093065526814367)] not found in axis'"
     ]
    }
   ],
   "source": [
    "df = df.drop(top_10_negative_features, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2113d4a1ed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(256,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       114\n",
      "           1       0.62      0.73      0.67       208\n",
      "           2       0.57      0.74      0.64       219\n",
      "           3       0.33      0.30      0.32       105\n",
      "           4       0.89      0.90      0.90       785\n",
      "           5       0.57      0.53      0.55       197\n",
      "           6       0.84      0.82      0.83        66\n",
      "           7       0.77      0.72      0.74       767\n",
      "           8       0.38      0.27      0.32        55\n",
      "           9       0.47      0.43      0.45       180\n",
      "          10       0.79      0.89      0.84       121\n",
      "          11       0.88      0.81      0.84       602\n",
      "          12       0.77      0.80      0.79       131\n",
      "          13       0.72      0.75      0.73        92\n",
      "\n",
      "    accuracy                           0.75      3642\n",
      "   macro avg       0.67      0.69      0.68      3642\n",
      "weighted avg       0.75      0.75      0.75      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features with Negative Impact on the Model (Overall):\n",
      "07 - 0.0069\n",
      "0b - 0.0053\n",
      "04 - 0.0044\n",
      "02 - 0.0036\n",
      "09 - 0.0032\n",
      "01 - 0.0028\n",
      "0a - 0.0024\n",
      "0d - 0.0023\n",
      "05 - 0.0018\n",
      "06 - 0.0016\n"
     ]
    }
   ],
   "source": [
    "all_class_feature_importances = []\n",
    "\n",
    "for class_index in range(num_classes):\n",
    "    shap_values_class = shap_values[class_index].values\n",
    "    mean_abs_shap_values = np.mean(np.abs(shap_values_class), axis=0)\n",
    "    all_class_feature_importances.append(mean_abs_shap_values)\n",
    "\n",
    "all_class_feature_importances = np.array(all_class_feature_importances)\n",
    "\n",
    "overall_feature_importances = np.mean(all_class_feature_importances, axis=0)\n",
    "\n",
    "# Sort and print the top 10 features that negatively impact the model\n",
    "sorted_feature_importances = sorted(enumerate(overall_feature_importances), key=lambda x: x[1], reverse=True)\n",
    "top_10_negative_features = sorted_feature_importances[:10]\n",
    "\n",
    "print(\"Top 10 Features with Negative Impact on the Model (Overall):\")\n",
    "for feature_idx, importance in top_10_negative_features:\n",
    "    print(f\"{feature_names[feature_idx]} - {importance:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted_feature_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 3643it [10:21,  5.77it/s]                                                                       \n",
      "Permutation explainer: 3643it [08:31,  6.99it/s]                                                                       \n",
      "Permutation explainer: 3643it [08:55,  6.66it/s]                                                                       \n",
      "Permutation explainer: 3643it [08:20,  7.13it/s]                                                                       \n",
      "Permutation explainer: 3643it [08:25,  7.05it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:42,  7.70it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:37,  7.78it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:59,  7.45it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:45,  7.65it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:44,  7.68it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:40,  7.73it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:45,  7.66it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:47,  7.62it/s]                                                                       \n",
      "Permutation explainer: 3643it [07:41,  7.72it/s]                                                                       \n"
     ]
    }
   ],
   "source": [
    "shap_values_classwise = []\n",
    "\n",
    "# Calculate SHAP values for each class separately\n",
    "for i in range(num_classes):\n",
    "    shap_values = explainer(X_test.values, max_evals=1000, outputs=i)  # Calculate SHAP values for class i\n",
    "    shap_values_classwise.append(shap_values)\n",
    "\n",
    "# Calculate the mean SHAP values across all classes\n",
    "mean_shap_values = np.mean(shap_values_classwise, axis=0)\n",
    "\n",
    "mean_abs_shap_values = np.mean(np.abs(mean_shap_values.values), axis=0)\n",
    "\n",
    "sorted_feature_importances = sorted(enumerate(mean_abs_shap_values), key=lambda x: x[1], reverse=True)\n",
    "top_20_negative_features = sorted_feature_importances[:20]\n",
    "\n",
    "print(\"Top 20 Features with Negative Impact on the Model:\")\n",
    "for feature_idx, importance in top_20_negative_features:\n",
    "    print(f\"{feature_names[feature_idx]} - {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
