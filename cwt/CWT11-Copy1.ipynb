{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtoMPNIKv0u-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import argparse\n",
    "import pywt\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Activation, Concatenate\n",
    "from keras import Sequential\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Different Transfer learning rate/models\n",
    "#https://keras.io/api/applications/\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5vHjlm8v4AV"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "df_train = pd.read_excel(\"gasoline.xlsx\", header=None) #trainning data\n",
    "df_train_label = pd.read_excel(\"gasoline.xlsx\", sheet_name=1, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmxN1NknLbLC"
   },
   "outputs": [],
   "source": [
    "#validation dataset\n",
    "df_regular = pd.read_excel(\"regular.xlsx\", header=None)\n",
    "df_regular_label = pd.read_excel(\"regular.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "df_midgrade = pd.read_excel(\"midgrade.xlsx\", header=None)\n",
    "df_midgrade_label = pd.read_excel(\"midgrade.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "df_premium = pd.read_excel(\"premium.xlsx\", header=None)\n",
    "df_premium_label = pd.read_excel(\"premium.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "#merge all three docs to get validation dataframe\n",
    "df_validation = df_regular.append(df_midgrade, ignore_index = True)\n",
    "df_validation = df_validation.append(df_premium, ignore_index = True)\n",
    "\n",
    "\n",
    "df_validation_label = df_regular_label.append(df_midgrade_label, ignore_index = True)\n",
    "df_validation_label = df_validation_label.append(df_premium_label, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oLsBs_EW1R5"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(\"weathered gasoline.xlsx\", header=None)\n",
    "df_test_label = pd.read_excel(\"weathered gasoline.xlsx\", sheet_name=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-blizykptaZ"
   },
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "df_train_label = df_train_label.iloc[: , 1:]\n",
    "\n",
    "df_validation_label = df_validation_label.iloc[: , 0:1]\n",
    "\n",
    "df_test_label = df_test_label.iloc[: , 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1GAUCZ8xY4H",
    "outputId": "4e2ad016-d0a7-4e9c-b45c-468334233da7"
   },
   "outputs": [],
   "source": [
    "#check shapes and data of dataframes\n",
    "print(df_train.shape)\n",
    "print(df_train_label.shape)\n",
    "\n",
    "print(df_validation.shape)\n",
    "print(df_validation_label.shape)\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "Ahj_6bJlhnBS",
    "outputId": "01510440-40cd-49d9-fae7-af9e36328c0e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#used to create a sample signal\n",
    "t = np.linspace(0, 1, num=1901)\n",
    "for row in df_train.itertuples():\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot(t, df_train.iloc[row.Index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsrCVfVuH6Nk"
   },
   "outputs": [],
   "source": [
    "def create_scalograms(dataframe, dataframe_label, path):\n",
    "    ids = []\n",
    "    names = []\n",
    "  \n",
    "    for row in dataframe.itertuples():\n",
    "        coef, freq = pywt.cwt(dataframe.iloc[row.Index], np.arange(1, 1901), 'gaus1')\n",
    "        signal = abs(coef)\n",
    "\n",
    "        filepath = path\n",
    "    \n",
    "        id = 'image' + str(row.Index)\n",
    "        name = 'image' + str(row.Index) + '.jpg'\n",
    "\n",
    "        ids.append(id)\n",
    "        names.append(name)  \n",
    "\n",
    "    #type = dataframe_label.iat[row.Index, 0]\n",
    "    \n",
    "    \n",
    "  \n",
    "    #filepath = path + type.lower() + '/' \n",
    "        filepath = path\n",
    "\n",
    "        plt.ioff()\n",
    "        plt.figure(figsize=(2.24, 2.24), dpi=200) #the dimension is multplied by the dpi to get display size\n",
    "        plt.imshow(signal, cmap='inferno')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(filepath + name, dpi=100, bbox_inches='tight',pad_inches = 0)\n",
    "        plt.close()\n",
    "\n",
    "        filepath = ''\n",
    "\n",
    "    dataframe_label['Image_id'] = ids\n",
    "    dataframe_label['Name'] = names\n",
    "\n",
    "    return dataframe_label\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavelet(signal, path, scales = np.arange(0.25, 512),\n",
    "\n",
    "                    waveletname = 'morl', #'cmor',\n",
    "\n",
    "                   cmap = plt.cm.seismic,\n",
    "\n",
    "                   title = 'Wavelet Transform (Power Spectrum) of signal',\n",
    "\n",
    "                   ylabel = 'Scales',\n",
    "\n",
    "                   xlabel = 'Time'):\n",
    "    \n",
    "    \n",
    "    #decode the signal\n",
    "    \n",
    "    time = np.arange(len(signal))\n",
    "    \n",
    "    dt = time[1] - time[0]\n",
    "\n",
    "    [coefficients, frequencies] = pywt.cwt(signal, scales, waveletname, dt)\n",
    "\n",
    "    power = (abs(coefficients)) ** 2\n",
    "\n",
    "   \n",
    "\n",
    "    period = 1. / frequencies\n",
    "\n",
    "    maxVal = power.max()\n",
    "    \n",
    "    n = 8\n",
    "\n",
    "    levels = [maxVal/(2**(n-i)) for i in range(n)]\n",
    "\n",
    "    contourlevels = np.log2(levels)\n",
    "\n",
    "    #print(power.min(), power.max())\n",
    "    \n",
    "   \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(2.24, 2.24), dpi=200)\n",
    "\n",
    "    im = ax.contourf(time, np.log2(period), np.log2(power), contourlevels, extend='both',cmap=cmap)\n",
    "\n",
    "   \n",
    "\n",
    " \n",
    "\n",
    "    #ax.set_title(title, fontsize=20)\n",
    "\n",
    "    #ax.set_ylabel(ylabel, fontsize=18)\n",
    "\n",
    "    #ax.set_xlabel(xlabel, fontsize=18)\n",
    "\n",
    "   \n",
    "\n",
    "   # yticks = 2**np.arange(np.ceil(np.log2(period.min())), np.ceil(np.log2(period.max())))\n",
    "\n",
    "    #ax.set_yticks(np.log2(yticks))\n",
    "\n",
    "    #ax.set_yticklabels(yticks)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    #ax.set_ylim(ylim[0], -1)\n",
    "\n",
    "   \n",
    "\n",
    "    #cbar_ax = fig.add_axes([0.95, 0.5, 0.03, 0.25])\n",
    "\n",
    "    #fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\")\n",
    "    \n",
    "    \n",
    "    plt.ioff()\n",
    "   \n",
    "    plt.axis('off')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.savefig(path,  bbox_inches='tight',pad_inches = 0)\n",
    "    \n",
    "\n",
    "    #plt.savefig(\"test.png\",  bbox_inches='tight',pad_inches = 0)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wavelet(df_train.iloc[80], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('test.png').convert('RGB')\n",
    "\n",
    "imgs = np.empty((0, 347, 338, 3)) \n",
    "\n",
    "imgs = np.append(imgs, np.array(img).reshape((1, 347, 338, 3)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rMLYY0b6p1y"
   },
   "outputs": [],
   "source": [
    "train_path = 'scalograms/train/'\n",
    "validation_path = 'scalograms/validation/'\n",
    "test_path = 'scalograms/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_label.columns =['Class']\n",
    "\n",
    "ids = []\n",
    "names = []\n",
    "\n",
    "for row in df_train.itertuples():\n",
    "    \n",
    "    image_id = 'image' + str(row.Index)\n",
    "    name = 'image' + str(row.Index) + '.png'\n",
    "\n",
    "    ids.append(image_id)\n",
    "    names.append(name)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    filepath = train_path + name\n",
    "        \n",
    "    plot_wavelet(df_train.iloc[row.Index], filepath)\n",
    "        \n",
    "#df_train_label['Image_id'] = ids\n",
    "#df_train_label['Name'] = names\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_validation_label.columns =['Class']\n",
    "ids = []\n",
    "names = []\n",
    "\n",
    "for row in df_validation.itertuples():\n",
    "    \n",
    "    image_id = 'image' + str(row.Index)\n",
    "    name = 'image' + str(row.Index) + '.png'\n",
    "\n",
    "    ids.append(image_id)\n",
    "    names.append(name)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    filepath = validation_path + name\n",
    "        \n",
    "    plot_wavelet(df_validation.iloc[row.Index], filepath)\n",
    "        \n",
    "#df_validation_label['Image_id'] = ids\n",
    "#df_validation_label['Name'] = names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2iM2GwpiVay",
    "outputId": "35681c5d-1b05-4b94-e8dc-7ce08d9938c2"
   },
   "outputs": [],
   "source": [
    "df_train_label.columns =['Class']\n",
    "df_train_label = create_scalograms(df_train, df_train_label, train_path)\n",
    "\n",
    "df_validation_label.columns =['Class']\n",
    "df_validation_label = create_scalograms(df_validation, df_validation_label, validation_path)\n",
    "\n",
    "df_test_label.columns =['Class']\n",
    "df_test_label['Class'] = df_test_label['Class'].replace(['midgrade'],'mid-grade')\n",
    "df_test_label = create_scalograms(df_test, df_test_label, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDiBHp96VX_9"
   },
   "outputs": [],
   "source": [
    "img_width = 347\n",
    "img_height = 338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuM6vaTh1iod"
   },
   "outputs": [],
   "source": [
    "def extract_scalogram(path):\n",
    "    height =  img_height# pixels in length\n",
    "    width = img_width # pixels in width\n",
    "  \n",
    "    imgs = np.empty((0, height, width, 3)) \n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        \n",
    "        if filename.endswith(\".png\"):\n",
    "\n",
    "            img = Image.open(os.path.join(path, filename)).convert('RGB')\n",
    "\n",
    "            imgs = np.append(imgs, np.array(img).reshape((1, height, width, 3)), axis=0)\n",
    "    \n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DTNQ8Co_ghr"
   },
   "outputs": [],
   "source": [
    "X_train = extract_scalogram(train_path)\n",
    "X_validation = extract_scalogram(validation_path)\n",
    "#X_test = extract_scalogram(test_path)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_train_label['Class_int'] = pd.Categorical(df_train_label['Class']).codes\n",
    "df_validation_label['Class_int'] = pd.Categorical(df_validation_label['Class']).codes\n",
    "#df_test_label['Class_int'] = pd.Categorical(df_test_label['Class']).codes\n",
    "\n",
    "y_train = df_train_label['Class_int']\n",
    "y_validation = df_validation_label['Class_int']\n",
    "#y_test = df_test_label['Class_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqrIQWmDDx5x"
   },
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_validation=to_categorical(y_validation)\n",
    "#y_test=to_categorical(y_test)\n",
    "\n",
    "#Verifying the dimension after one hot encoding\n",
    "print((X_train.shape,y_train.shape))\n",
    "print((X_validation.shape,y_validation.shape))\n",
    "#print((X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cawLUYxo9x1T"
   },
   "outputs": [],
   "source": [
    "def normalize_negative_one(img):\n",
    "    normalized_input = (img - np.amin(img)) / (np.amax(img) - np.amin(img))\n",
    "    return 2*normalized_input - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icmv_rTs91mu"
   },
   "outputs": [],
   "source": [
    "#X_train = normalize_negative_one(X_train)\n",
    "#X_validation = normalize_negative_one(X_validation)\n",
    "#X_test = normalize_negative_one(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9zr0H7_NdTV"
   },
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "batch_size= 16\n",
    "epochs=10\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-EI_fgGEOIP"
   },
   "outputs": [],
   "source": [
    "#Image Data Augmentation -  technique of altering the existing data to create some more data for the model training proces\n",
    "\n",
    "train_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "train_generator = train_dategen.flow(X_train,  y_train, batch_size= batch_size)\n",
    "\n",
    "validation_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "validation_generator = validation_dategen.flow(X_validation, y_validation, batch_size= batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1./255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D9Z61UHNXAF"
   },
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5) #change learning rATE  to get the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W6cNDTONZ5j"
   },
   "outputs": [],
   "source": [
    "#Defining the googlenet model\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#base_model = InceptionV3(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = ResNet50(include_top = False, weights = 'imagenet', input_shape = (169,169,3)) #\n",
    "# base_model = ResNet101(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "base_model = Xception(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "\n",
    "\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#changing the last layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "#https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n",
    "\n",
    "# #changing the last layer\n",
    "# for layer in base_model.layers:\n",
    "#   layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zURWTWz7MAyU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YfCWpb4ZSK2"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRMSALYswHVJ"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    epochs = epochs, \n",
    "                    steps_per_epoch = X_train.shape[0]//batch_size, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = X_validation.shape[0]//batch_size, callbacks=[lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSiqE6RyFjV7"
   },
   "outputs": [],
   "source": [
    "#Plotting the training and validation loss and accuracy\n",
    "f,ax=plt.subplots(2,1) \n",
    "\n",
    "#Loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11rtDrj_FjIn"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgpiOLlg3vC1"
   },
   "outputs": [],
   "source": [
    "print(y_pred) #predict what class the test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
