{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TtoMPNIKv0u-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "import argparse\n",
    "import pywt\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Activation, Concatenate\n",
    "from keras import Sequential\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Different Transfer learning rate/models\n",
    "#https://keras.io/api/applications/\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEXOXxnHf531",
    "outputId": "d080d502-47e2-4740-ee41-4be3201d114a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cgau1',\n",
       " 'cgau2',\n",
       " 'cgau3',\n",
       " 'cgau4',\n",
       " 'cgau5',\n",
       " 'cgau6',\n",
       " 'cgau7',\n",
       " 'cgau8',\n",
       " 'cmor',\n",
       " 'fbsp',\n",
       " 'gaus1',\n",
       " 'gaus2',\n",
       " 'gaus3',\n",
       " 'gaus4',\n",
       " 'gaus5',\n",
       " 'gaus6',\n",
       " 'gaus7',\n",
       " 'gaus8',\n",
       " 'mexh',\n",
       " 'morl',\n",
       " 'shan']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavlist = pywt.wavelist(kind='continuous')\n",
    "wavlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v5vHjlm8v4AV"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gasoline.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#train dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgasoline.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#trainning data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_train_label \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgasoline.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gasoline.xlsx'"
     ]
    }
   ],
   "source": [
    "#train dataset\n",
    "df_train = pd.read_excel(\"gasoline.xlsx\", header=None) #trainning data\n",
    "df_train_label = pd.read_excel(\"gasoline.xlsx\", sheet_name=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmxN1NknLbLC"
   },
   "outputs": [],
   "source": [
    "#validation dataset\n",
    "df_regular = pd.read_excel(\"regular.xlsx\", header=None)\n",
    "df_regular_label = pd.read_excel(\"regular.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "df_midgrade = pd.read_excel(\"midgrade.xlsx\", header=None)\n",
    "df_midgrade_label = pd.read_excel(\"midgrade.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "df_premium = pd.read_excel(\"premium.xlsx\", header=None)\n",
    "df_premium_label = pd.read_excel(\"premium.xlsx\", sheet_name=1, header=None)\n",
    "\n",
    "#merge all three docs to get validation dataframe\n",
    "df_validation = df_regular.append(df_midgrade, ignore_index = True)\n",
    "df_validation = df_validation.append(df_premium, ignore_index = True)\n",
    "\n",
    "\n",
    "df_validation_label = df_regular_label.append(df_midgrade_label, ignore_index = True)\n",
    "df_validation_label = df_validation_label.append(df_premium_label, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oLsBs_EW1R5"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(\"weathered gasoline.xlsx\", header=None)\n",
    "df_test_label = pd.read_excel(\"weathered gasoline.xlsx\", sheet_name=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-blizykptaZ"
   },
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "df_train_label = df_train_label.iloc[: , 1:]\n",
    "\n",
    "df_validation_label = df_validation_label.iloc[: , 0:1]\n",
    "\n",
    "df_test_label = df_test_label.iloc[: , 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1GAUCZ8xY4H",
    "outputId": "4e2ad016-d0a7-4e9c-b45c-468334233da7"
   },
   "outputs": [],
   "source": [
    "#check shapes and data of dataframes\n",
    "print(df_train.shape)\n",
    "print(df_train_label.shape)\n",
    "\n",
    "print(df_validation.shape)\n",
    "print(df_validation_label.shape)\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "Ahj_6bJlhnBS",
    "outputId": "01510440-40cd-49d9-fae7-af9e36328c0e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#used to create a sample signal\n",
    "t = np.linspace(0, 1, num=1901)\n",
    "for row in df_train.itertuples():\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot(t, df_train.iloc[row.Index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsrCVfVuH6Nk"
   },
   "outputs": [],
   "source": [
    "def create_scalograms(dataframe, dataframe_label, path):\n",
    "  '''\n",
    "  Method used to create scalograms and save them as image which\n",
    "  are used as CNN input\n",
    "  '''\n",
    "\n",
    "  ids = []\n",
    "  names = []\n",
    "  \n",
    "  for row in dataframe.itertuples():\n",
    "  \n",
    "    #if row.Index in range(5, 10):\n",
    "    coef, freq = pywt.cwt(dataframe.iloc[row.Index], np.arange(1, 1901), 'gaus1')\n",
    "    signal = abs(coef)\n",
    "\n",
    "    filepath = path\n",
    "    \n",
    "    id = 'image' + str(row.Index)\n",
    "    name = 'image' + str(row.Index) + '.jpg'\n",
    "\n",
    "    ids.append(id)\n",
    "    names.append(name)  \n",
    "\n",
    "    #type = dataframe_label.iat[row.Index, 0]\n",
    "    \n",
    "    \n",
    "  \n",
    "    #filepath = path + type.lower() + '/' \n",
    "    filepath = path\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.figure(figsize=(2.24, 2.24), dpi=200) #the dimension is multplied by the dpi to get display size\n",
    "    plt.imshow(signal, cmap='inferno')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filepath + name, dpi=100, bbox_inches='tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "\n",
    "    filepath = ''\n",
    "\n",
    "    dataframe_label['Image_id'] = ids\n",
    "    dataframe_label['Name'] = names\n",
    "\n",
    "    return dataframe_label\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rMLYY0b6p1y"
   },
   "outputs": [],
   "source": [
    "train_path = 'scalograms/train/'\n",
    "validation_path = 'scalograms/validation/'\n",
    "test_path = 'scalograms/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2iM2GwpiVay",
    "outputId": "35681c5d-1b05-4b94-e8dc-7ce08d9938c2"
   },
   "outputs": [],
   "source": [
    "df_train_label.columns =['Class']\n",
    "df_train_label = create_scalograms(df_train, df_train_label, train_path)\n",
    "\n",
    "df_validation_label.columns =['Class']\n",
    "df_validation_label = create_scalograms(df_validation, df_validation_label, validation_path)\n",
    "\n",
    "df_test_label.columns =['Class']\n",
    "df_test_label['Class'] = df_test_label['Class'].replace(['midgrade'],'mid-grade')\n",
    "df_test_label = create_scalograms(df_test, df_test_label, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDiBHp96VX_9"
   },
   "outputs": [],
   "source": [
    "img_width = 169\n",
    "img_height = 169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuM6vaTh1iod"
   },
   "outputs": [],
   "source": [
    "def extract_scalogram(path):\n",
    "  \n",
    "  height =  img_height# pixels in length\n",
    "  width = img_width # pixels in width\n",
    "  \n",
    "  imgs = np.empty((0, height, width, 3)) \n",
    "\n",
    "  for filename in os.listdir(path):\n",
    "    \n",
    "    if filename.endswith(\".jpg\"):\n",
    "\n",
    "        img = Image.open(os.path.join(path, filename)).convert('RGB')\n",
    "\n",
    "        imgs = np.append(imgs, np.array(img).reshape((1, height, width, 3)), axis=0)\n",
    "\n",
    "      \n",
    "  return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DTNQ8Co_ghr"
   },
   "outputs": [],
   "source": [
    "X_train = extract_scalogram(train_path)\n",
    "X_validation = extract_scalogram(validation_path)\n",
    "X_test = extract_scalogram(test_path)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_train_label['Class_int'] = pd.Categorical(df_train_label['Class']).codes\n",
    "df_validation_label['Class_int'] = pd.Categorical(df_validation_label['Class']).codes\n",
    "df_test_label['Class_int'] = pd.Categorical(df_test_label['Class']).codes\n",
    "\n",
    "y_train = df_train_label['Class_int']\n",
    "y_validation = df_validation_label['Class_int']\n",
    "y_test = df_test_label['Class_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqrIQWmDDx5x"
   },
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_validation=to_categorical(y_validation)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "#Verifying the dimension after one hot encoding\n",
    "print((X_train.shape,y_train.shape))\n",
    "print((X_validation.shape,y_validation.shape))\n",
    "print((X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cawLUYxo9x1T"
   },
   "outputs": [],
   "source": [
    "def normalize_negative_one(img):\n",
    "    normalized_input = (img - np.amin(img)) / (np.amax(img) - np.amin(img))\n",
    "    return 2*normalized_input - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icmv_rTs91mu"
   },
   "outputs": [],
   "source": [
    "#X_train = normalize_negative_one(X_train)\n",
    "#X_validation = normalize_negative_one(X_validation)\n",
    "#X_test = normalize_negative_one(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9zr0H7_NdTV"
   },
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "batch_size= 16\n",
    "epochs=10\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-EI_fgGEOIP"
   },
   "outputs": [],
   "source": [
    "#Image Data Augmentation -  technique of altering the existing data to create some more data for the model training proces\n",
    "\n",
    "train_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "train_generator = train_dategen.flow(X_train,  y_train, batch_size= batch_size)\n",
    "\n",
    "validation_dategen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "validation_generator = validation_dategen.flow(X_validation, y_validation, batch_size= batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1./255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D9Z61UHNXAF"
   },
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W6cNDTONZ5j"
   },
   "outputs": [],
   "source": [
    "#Defining the googlenet model\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#base_model = InceptionV3(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "base_model = ResNet50(include_top = False, weights = 'imagenet', input_shape = (169,169,3)) #\n",
    "# base_model = ResNet101(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = Xception(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "# base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (169,169,3))\n",
    "\n",
    "\n",
    "#use resnet - try various versions of resnet\n",
    "#compare googlenet to resnet and the other 4, to see which one is better. use the latest version of them\n",
    "\n",
    "#changing the last layer\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "#changing the last layer\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if feature_extract_option == 0:\n",
    "#         backbone_model = ResNet50(weights='imagenet')\n",
    "#         backbone_model = Model(inputs=backbone_model.input, outputs=backbone_model.get_layer(index=-2).output)\n",
    "#         data.model = backbone_model\n",
    "#         data.extract_features(image_path, option='fixed frame amount', number_of_frames=190)\n",
    "#     elif feature_extract_option == 1:\n",
    "#         data.video_features = DataSet.loader(image_path + feature_path)\n",
    "\n",
    "#     return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_gen, preproc_fn, target_size in [(InceptionV3, iv3.preprocess_input, model_sizes['InceptionV3']),\n",
    "#                                       (Xception, xcpt.preprocess_input, model_sizes['Xception']),\n",
    "#                                       (ResNet50, rsnt.preprocess_input, model_sizes['ResNet50'])]:\n",
    "\n",
    "#             keras_model = model_gen(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zURWTWz7MAyU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YfCWpb4ZSK2"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRMSALYswHVJ"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    epochs = epochs, \n",
    "                    steps_per_epoch = X_train.shape[0]//batch_size, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = X_validation.shape[0]//batch_size, callbacks=[lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSiqE6RyFjV7"
   },
   "outputs": [],
   "source": [
    "#Plotting the training and validation loss and accuracy\n",
    "f,ax=plt.subplots(2,1) \n",
    "\n",
    "#Loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11rtDrj_FjIn"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgpiOLlg3vC1"
   },
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THyAiuIzHutj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_DOZNCZHupZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Uvd3idY3zwl"
   },
   "outputs": [],
   "source": [
    "# coef, freq = pywt.cwt(df_train.iloc[80], np.arange(1, 1901), 'shan')\n",
    "# signal = abs(coef)\n",
    "# t = np.linspace(0, 1, num=1901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMl5ayCToPBb"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(2.24, 2.24), dpi=200) #the dimension is multplied by the dpi to get display size\n",
    "# plt.imshow(signal, cmap='cividis')\n",
    "# plt.axis('off')\n",
    "# plt.savefig('test.jpg', dpi=100, bbox_inches='tight',pad_inches = 0) #the dimension is multplied by the dpi to get storage size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJ52j1QY6Uiv"
   },
   "outputs": [],
   "source": [
    "#X, Y = np.meshgrid(t, signal)\n",
    "#Z1 = np.exp(-X**2 - Y**2)\n",
    "#Z2 = np.exp(-(X - 1)**2 - (Y - 1)**2)\n",
    "#Z = (Z1 - Z2) * 2\n",
    "#fig, ax = plt.subplots()\n",
    "#CS = ax.contour(X, Y, Z)\n",
    "#ax.clabel(CS, inline=True, fontsize=10)\n",
    "#ax.set_title('Simplest default with labels')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
